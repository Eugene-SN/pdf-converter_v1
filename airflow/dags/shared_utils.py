# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –û–±—â–∏–µ —É—Ç–∏–ª–∏—Ç—ã –∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã –¥–ª—è –º–æ–¥—É–ª—å–Ω—ã—Ö DAG
# PDF Converter Pipeline v4.0 - –£–°–¢–†–ê–ù–ï–ù–ò–ï –ü–†–û–ë–õ–ï–ú OCR –ò –ü–û–¢–ï–†–ò –î–ê–ù–ù–´–•
# ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´:
# - –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ Document Processor
# - –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ use_ocr —Ñ–ª–∞–≥–∞
# - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω DocumentProcessorOperator
# - –£—Å—Ç—Ä–∞–Ω–µ–Ω–∞ –ø–æ—Ç–µ—Ä—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

from airflow.models import BaseOperator
from airflow.utils.decorators import apply_defaults
from airflow.utils.context import Context
import requests
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import os
import time

logger = logging.getLogger(__name__)

# =============================================================================
# –ë–ê–ó–û–í–´–ô –ö–õ–ê–°–° –î–õ–Ø –í–°–ï–• –û–ü–ï–†–ê–¢–û–†–û–í
# =============================================================================

class PDFConverterBaseOperator(BaseOperator):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ PDF –∫–æ–Ω–≤–µ–π–µ—Ä–∞"""

    @apply_defaults
    def __init__(
        self,
        service_endpoint: str,
        timeout: int = 300,
        retry_count: int = 3,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.service_endpoint = service_endpoint
        self.timeout = timeout
        self.retry_count = retry_count

    def make_request(self, endpoint: str, method: str = 'POST', data: Dict = None, files: Dict = None) -> Dict:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ HTTP –∑–∞–ø—Ä–æ—Å–∞ –∫ —Å–µ—Ä–≤–∏—Å—É —Å retry –ª–æ–≥–∏–∫–æ–π"""
        url = f"{self.service_endpoint}{endpoint}"
        
        for attempt in range(self.retry_count):
            try:
                if method == 'POST':
                    if files:
                        response = requests.post(url, data=data, files=files, timeout=self.timeout)
                    else:
                        response = requests.post(url, json=data, timeout=self.timeout)
                else:
                    response = requests.get(url, timeout=self.timeout)
                
                response.raise_for_status()
                return response.json()
            
            except Exception as e:
                logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ—É–¥–∞—á–Ω–∞: {str(e)}")
                if attempt == self.retry_count - 1:
                    raise
        
        return {}

# =============================================================================
# ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô DOCUMENT PROCESSOR OPERATOR
# =============================================================================

class DocumentProcessorOperator(PDFConverterBaseOperator):
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –æ–ø–µ—Ä–∞—Ç–æ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ PDF (DAG 1)"""
    
    template_fields = ('input_file_path', 'processing_options')

    @apply_defaults
    def __init__(
        self,
        input_file_path: str,
        processing_options: Dict[str, Any] = None,
        **kwargs
    ):
        super().__init__(
            service_endpoint=os.getenv('DOCUMENT_PROCESSOR_URL', 'http://document-processor:8001'),
            **kwargs
        )
        
        self.input_file_path = input_file_path
        self.processing_options = processing_options or {}

    def execute(self, context: Context) -> Dict[str, Any]:
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ PDF –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        import json
        
        logger.info(f"üìÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–∞: {self.input_file_path}")

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è processing_options
        if isinstance(self.processing_options, str):
            try:
                self.processing_options = json.loads(self.processing_options)
                logger.info("‚úÖ processing_options –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã –∏–∑ JSON –≤ dict")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å processing_options: {e}")
                self.processing_options = {}

        if not isinstance(self.processing_options, dict):
            logger.warning("‚ö†Ô∏è processing_options –Ω–µ dict, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            self.processing_options = {}

        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è API v4.0
        options_dict = {
            'use_ocr': self.processing_options.get('use_ocr', False),  # ‚úÖ –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é False
            'extract_tables': self.processing_options.get('extract_tables', True),
            'extract_images': self.processing_options.get('extract_images', True),
            'extract_formulas': self.processing_options.get('extract_formulas', True),
            'high_quality_ocr': self.processing_options.get('high_quality_ocr', True),
            'language': self.processing_options.get('language', 'zh-CN')
        }
        
        logger.info(f"üìã –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {options_dict}")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
        with open(self.input_file_path, 'rb') as file:
            files = {'file': file}
            data = {
                'options': json.dumps(options_dict)  # ‚úÖ –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º –≤ JSON-—Å—Ç—Ä–æ–∫—É
            }
            
            result = self.make_request('/convert', files=files, data=data)

        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ API v4.0
        if not result or not result.get('success'):
            raise Exception(f"Document Processor API –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É: {result.get('message', 'Unknown error')}")
        
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ extracted_data
        extracted_data = {
            'success': result.get('success', False),
            'processing_time': result.get('processing_time', 0),
            'document_id': result.get('document_id', ''),
            
            # ‚úÖ –ì–õ–ê–í–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ sections
            'extracted_text': self._extract_full_text_from_result(result),
            
            # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            'document_structure': {
                'pages': result.get('pages_count', 0),
                'sections': result.get('sections_count', 0),
                'tables': result.get('tables_count', 0),
                'images': result.get('images_count', 0),
                'formulas': result.get('formulas_count', 0)
            },
            
            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            'metadata': result.get('metadata', {}),
            'output_files': result.get('output_files', []),
            
            # ‚úÖ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö DAG
            'sections': self._extract_sections_data(result),
            'tables': self._extract_tables_data(result),
            'images': self._extract_images_data(result),
            
            'processing_stats': {
                'processing_time': result.get('processing_time', 0),
                'success': result.get('success', False),
                'document_id': result.get('document_id', ''),
                'output_files': result.get('output_files', [])
            }
        }

        text_length = len(extracted_data['extracted_text'])
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ç–µ–∫—Å—Ç–∞: {text_length} —Å–∏–º–≤–æ–ª–æ–≤")
        
        if text_length < 50:
            logger.warning("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ò–∑–≤–ª–µ—á–µ–Ω–æ –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞! –í–æ–∑–º–æ–∂–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º.")
        
        return extracted_data

    def _extract_full_text_from_result(self, result: Dict[str, Any]) -> str:
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ API"""
        
        full_text = ""
        
        try:
            # –°–ø–æ—Å–æ–± 1: –ß–∏—Ç–∞–µ–º –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ JSON —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å output_files)
            output_files = result.get('output_files', [])
            if output_files:
                try:
                    json_file_path = output_files[0]  # –ü–µ—Ä–≤—ã–π —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å JSON
                    if os.path.exists(json_file_path):
                        with open(json_file_path, 'r', encoding='utf-8') as f:
                            json_data = json.load(f)
                            
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ sections
                        sections = json_data.get('sections', [])
                        for section in sections:
                            if isinstance(section, dict):
                                if 'title' in section and section['title']:
                                    full_text += f"# {section['title']}\n\n"
                                if 'content' in section and section['content']:
                                    full_text += section['content'] + "\n\n"
                        
                        if full_text and len(full_text) > 50:
                            logger.info(f"‚úÖ –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω –∏–∑ JSON —Ñ–∞–π–ª–∞: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                            return full_text
                            
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å JSON —Ñ–∞–π–ª: {e}")
            
            # –°–ø–æ—Å–æ–± 2: –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ metadata (–µ—Å–ª–∏ –µ—Å—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
            metadata = result.get('metadata', {})
            if metadata and isinstance(metadata, dict):
                # –ò—â–µ–º –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö metadata
                for key in ['extracted_content', 'document_content', 'full_text', 'text_content']:
                    if key in metadata and metadata[key]:
                        content = metadata[key]
                        if isinstance(content, str) and len(content) > 50:
                            logger.info(f"‚úÖ –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω –∏–∑ metadata.{key}: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                            return content
            
            # –°–ø–æ—Å–æ–± 3: –ò—Å–ø–æ–ª—å–∑—É–µ–º message –∫–∞–∫ fallback
            if 'message' in result and result['message']:
                message = result['message']
                if len(message) > 50:
                    logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–µ message: {len(message)} —Å–∏–º–≤–æ–ª–æ–≤")
                    return message
            
            # –°–ø–æ—Å–æ–± 4: –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–∫—É–º–µ–Ω—Ç–µ
            fallback_text = f"""–î–æ–∫—É–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ.

–°—Ç—Ä–∞–Ω–∏—Ü: {result.get('pages_count', 0)}
–°–µ–∫—Ü–∏–π: {result.get('sections_count', 0)}
–¢–∞–±–ª–∏—Ü: {result.get('tables_count', 0)}
–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {result.get('images_count', 0)}

–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.get('processing_time', 0)} —Å–µ–∫—É–Ω–¥
ID –¥–æ–∫—É–º–µ–Ω—Ç–∞: {result.get('document_id', 'unknown')}
"""
            
            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
            return fallback_text
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
            return f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {str(e)}"

    def _extract_sections_data(self, result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–µ–∫—Ü–∏–π –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö DAG"""
        sections = []
        
        try:
            # –ß–∏—Ç–∞–µ–º –∏–∑ JSON —Ñ–∞–π–ª–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
            output_files = result.get('output_files', [])
            if output_files and os.path.exists(output_files[0]):
                with open(output_files[0], 'r', encoding='utf-8') as f:
                    json_data = json.load(f)
                    sections = json_data.get('sections', [])
            
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å–µ–∫—Ü–∏–∏: {e}")
        
        return sections

    def _extract_tables_data(self, result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö DAG"""
        tables = []
        
        try:
            # –ß–∏—Ç–∞–µ–º –∏–∑ JSON —Ñ–∞–π–ª–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
            output_files = result.get('output_files', [])
            if output_files and os.path.exists(output_files[0]):
                with open(output_files[0], 'r', encoding='utf-8') as f:
                    json_data = json.load(f)
                    tables = json_data.get('tables', [])
            
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–∞–±–ª–∏—Ü—ã: {e}")
        
        return tables

    def _extract_images_data(self, result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö DAG"""
        images = []
        
        try:
            # –ß–∏—Ç–∞–µ–º –∏–∑ JSON —Ñ–∞–π–ª–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
            output_files = result.get('output_files', [])
            if output_files and os.path.exists(output_files[0]):
                with open(output_files[0], 'r', encoding='utf-8') as f:
                    json_data = json.load(f)
                    images = json_data.get('images', [])
            
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        
        return images

# =============================================================================
# DYNAMIC vLLM OPERATOR - –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô
# =============================================================================

class DynamicVLLMOperator(PDFConverterBaseOperator):
    """
    –û–ø–µ—Ä–∞—Ç–æ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Dynamic vLLM Server
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –Ω—É–∂–Ω—É—é –º–æ–¥–µ–ª—å –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏
    """

    @apply_defaults
    def __init__(
        self,
        task_type: str,  # 'content_transformation' –∏–ª–∏ 'translation'
        system_prompt: str = None,
        user_prompt_template: str = None,
        temperature: float = 0.1,
        max_tokens: int = 4096,
        **kwargs
    ):
        super().__init__(
            service_endpoint=os.getenv('VLLM_SERVER_URL', 'http://vllm-server:8000'),
            timeout=1800,  # –£–≤–µ–ª–∏—á–µ–Ω —Ç–∞–π–º–∞—É—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π
            **kwargs
        )
        
        self.task_type = task_type
        self.system_prompt = system_prompt
        self.user_prompt_template = user_prompt_template
        self.temperature = temperature
        self.max_tokens = max_tokens

    def _wait_for_model_ready(self, max_wait_time: int = 600) -> bool:
        """–û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –∫ —Ä–∞–±–æ—Ç–µ"""
        start_time = time.time()
        
        while time.time() - start_time < max_wait_time:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å —á–µ—Ä–µ–∑ health endpoint
                response = requests.get(f"{self.service_endpoint}/health", timeout=10)
                if response.status_code == 200:
                    health_data = response.json()
                    if health_data.get('status') == 'healthy':
                        logger.info("‚úÖ Dynamic vLLM Server –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
                        return True
                    else:
                        logger.info(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞: {health_data.get('status', 'unknown')}")
                else:
                    logger.debug(f"Health check failed with status {response.status_code}")
            except Exception as e:
                logger.debug(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
            
            time.sleep(10)
        
        logger.error(f"‚ùå –¢–∞–π–º-–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞ ({max_wait_time}s)")
        return False

    def _get_current_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏"""
        try:
            response = requests.get(f"{self.service_endpoint}/v1/models/status", timeout=30)
            if response.status_code == 200:
                return response.json()
            else:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏: {response.status_code}")
                return {}
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏: {e}")
            return {}

    def execute(self, context: Context) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ Dynamic vLLM API"""
        logger.info(f"üöÄ –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–¥–∞—á—É —Ç–∏–ø–∞: {self.task_type}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞
        if not self._wait_for_model_ready():
            raise RuntimeError("Dynamic vLLM Server –Ω–µ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏
        model_status = self._get_current_model_info()
        logger.info(f"üìä –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π: {model_status.get('manager_status', {})}")

        if self.task_type == 'content_transformation':
            return self._transform_content(context)
        elif self.task_type == 'translation':
            return self._translate_content(context)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –∑–∞–¥–∞—á–∏: {self.task_type}")

    def _transform_content(self, context: Context) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ Markdown"""
        logger.info("üîÑ –ó–∞–ø—É—Å–∫ Content Transformation")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
        upstream_data = context['task_instance'].xcom_pull(task_ids=None)
        if not upstream_data:
            raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç—Ç–∞–ø–∞")

        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        text_content = upstream_data.get('extracted_text', '')
        structure = upstream_data.get('document_structure', {})
        tables = upstream_data.get('tables', [])

        if not text_content or len(text_content) < 50:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏: {len(text_content)} —Å–∏–º–≤–æ–ª–æ–≤")

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π Markdown —Ñ–æ—Ä–º–∞—Ç.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:

1. –°–æ—Ö—Ä–∞–Ω–∏ –í–°–Æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–∑–∞–≥–æ–ª–æ–≤–∫–∏, –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏, —Ç–∞–±–ª–∏—Ü—ã)
2. –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ñ–æ—Ä–º–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ–º–∞–Ω–¥—ã IPMI/BMC/Redfish –≤ –±–ª–æ–∫–∞—Ö –∫–æ–¥–∞ ```
3. –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô
4. –°–æ–∑–¥–∞–π –ø—Ä–∞–≤–∏–ª—å–Ω—É—é markdown-—Ä–∞–∑–º–µ—Ç–∫—É –¥–ª—è —Ç–∞–±–ª–∏—Ü
5. –î–æ–±–∞–≤—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π (# ## ### ####)
6. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π thinking —Ç–µ–≥–∏
7. –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã"""

        user_prompt = f"""–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π –∏–∑ PDF —Ç–µ–∫—Å—Ç –≤ –∏–¥–µ–∞–ª—å–Ω—ã–π Markdown —Ñ–æ—Ä–º–∞—Ç.

–ò–°–•–û–î–ù–´–ô –¢–ï–ö–°–¢:

{text_content[:8000]}  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è –º–æ–¥–µ–ª–∏

{"–°–¢–†–£–ö–¢–£–†–ê –î–û–ö–£–ú–ï–ù–¢–ê:" if structure else ""}
{json.dumps(structure, ensure_ascii=False, indent=2) if structure else ""}

{"–¢–ê–ë–õ–ò–¶–´:" if tables else ""}
{json.dumps(tables, ensure_ascii=False, indent=2) if tables else ""}

–°–æ–∑–¥–∞–π —á–∏—Å—Ç—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Markdown –±–µ–∑ –ª–∏—à–Ω–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."""

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è Dynamic vLLM API
        request_data = {
            "model": "content-transformer",  # –ê–ª–∏–∞—Å –º–æ–¥–µ–ª–∏
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "task_type": "content_transformation",  # –£–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏ –¥–ª—è –∞–≤—Ç–æ–≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏
            "stream": False
        }

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        try:
            logger.info("üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Dynamic vLLM Server")
            response = requests.post(
                f"{self.service_endpoint}/v1/chat/completions",
                json=request_data,
                timeout=self.timeout
            )
            
            response.raise_for_status()
            result = response.json()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if 'choices' in result and len(result['choices']) > 0:
                transformed_content = result['choices'][0]['message']['content']

                # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ—Ü–µ—Å—Å–µ
                pdf_meta = result.get('pdf_converter_meta', {})
                logger.info(f"‚úÖ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ú–æ–¥–µ–ª—å: {pdf_meta.get('model_key', 'unknown')}")
                logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {pdf_meta.get('processing_time_seconds', 0)}s")
                logger.info(f"üîÑ –í—Å–µ–≥–æ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–π –º–æ–¥–µ–ª–µ–π: {pdf_meta.get('model_swaps_total', 0)}")

                return {
                    'markdown_content': transformed_content,
                    'original_structure': structure,
                    'transformation_stats': {
                        'input_length': len(text_content),
                        'output_length': len(transformed_content),
                        'tables_processed': len(tables),
                        'model_used': pdf_meta.get('model_key', 'unknown'),
                        'processing_time': pdf_meta.get('processing_time_seconds', 0),
                        'vram_used_gb': pdf_meta.get('vram_usage_gb', 0)
                    }
                }
            else:
                raise ValueError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç vLLM")

        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ vLLM: {e}")
            raise
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            raise

    def _translate_content(self, context: Context) -> Dict[str, Any]:
        """–ü–µ—Ä–µ–≤–æ–¥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤"""
        logger.info("üåê –ó–∞–ø—É—Å–∫ Translation Pipeline")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç—Ç–∞–ø–∞
        upstream_data = context['task_instance'].xcom_pull(task_ids=None)
        if not upstream_data:
            raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç—Ç–∞–ø–∞")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º Markdown –∫–æ–Ω—Ç–µ–Ω—Ç
        markdown_content = upstream_data.get('markdown_content', '')
        if not markdown_content:
            raise ValueError("–ù–µ—Ç Markdown –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")

        # –ü–æ–ª—É—á–∞–µ–º —Ü–µ–ª–µ–≤–æ–π —è–∑—ã–∫ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ DAG
        target_language = context['dag_run'].conf.get('target_language', 'ru')
        
        if target_language == 'original':
            logger.info("üîÑ –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫ 'original' - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥")
            return {
                'translated_content': markdown_content,
                'target_language': 'original',
                'translation_stats': {
                    'skipped': True,
                    'reason': 'original language requested'
                }
            }

        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–æ–≤
        language_prompts = {
            'ru': '–ü–µ—Ä–µ–≤–µ–¥–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫',
            'en': 'Translate technical document to English', 
            'zh': 'Â∞ÜÊäÄÊúØÊñáÊ°£ÁøªËØëÊàê‰∏≠Êñá'
        }

        system_prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–µ—Ä–µ–≤–æ–¥—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ {target_language}.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:

1. –ù–ï –ü–ï–†–ï–í–û–î–ò —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ–º–∞–Ω–¥—ã IPMI, BMC, Redfish
2. –ù–ï –ü–ï–†–ï–í–û–î–ò –Ω–∞–∑–≤–∞–Ω–∏—è –∞–ø–ø–∞—Ä–∞—Ç–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –∏ –º–æ–¥–µ–ª–∏
3. –ù–ï –ü–ï–†–ï–í–û–î–ò –±–ª–æ–∫–∏ –∫–æ–¥–∞ –≤ ``` –∏ –∫–æ–º–∞–Ω–¥—ã –≤ `
4. –°–û–•–†–ê–ù–ò –≤—Å—é Markdown —Ä–∞–∑–º–µ—Ç–∫—É (–∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏, —Ç–∞–±–ª–∏—Ü—ã)
5. –°–û–•–†–ê–ù–ò –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
6. –í–ê–ñ–ù–û: "ÈóÆÂ§©" –í–°–ï–ì–î–ê –ø–µ—Ä–µ–≤–æ–¥–∏ –∫–∞–∫ "WenTian", –ù–ï –∫–∞–∫ "ThinkSystem"
7. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π thinking —Ç–µ–≥–∏
8. –ü–µ—Ä–µ–≤–æ–¥–∏ –¢–û–õ–¨–ö–û –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏"""

        user_prompt = f"""{language_prompts.get(target_language, language_prompts['en'])}

–ò–°–•–û–î–ù–´–ô MARKDOWN:

{markdown_content[:8000]}  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

–°–æ–∑–¥–∞–π —Ç–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –≤—Å—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É."""

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è Dynamic vLLM API
        request_data = {
            "model": "translator",  # –ê–ª–∏–∞—Å –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–µ—Ä–µ–≤–æ–¥–∞
            "max_tokens": self.max_tokens,
            "task_type": "translation",  # –£–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏
            "stream": False
        }

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        try:
            logger.info("üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –ø–µ—Ä–µ–≤–æ–¥ –≤ Dynamic vLLM Server")
            response = requests.post(
                f"{self.service_endpoint}/v1/chat/completions",
                json=request_data,
                timeout=self.timeout
            )
            
            response.raise_for_status()
            result = response.json()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if 'choices' in result and len(result['choices']) > 0:
                translated_content = result['choices'][0]['message']['content']

                # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                pdf_meta = result.get('pdf_converter_meta', {})
                logger.info(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ú–æ–¥–µ–ª—å: {pdf_meta.get('model_key', 'unknown')}")
                logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {pdf_meta.get('processing_time_seconds', 0)}s")

                return {
                    'translated_content': translated_content,
                    'target_language': target_language,
                    'original_content': markdown_content,
                    'translation_stats': {
                        'input_length': len(markdown_content),
                        'output_length': len(translated_content),
                        'model_used': pdf_meta.get('model_key', 'unknown'),
                        'processing_time': pdf_meta.get('processing_time_seconds', 0),
                        'vram_used_gb': pdf_meta.get('vram_usage_gb', 0)
                    }
                }
            else:
                raise ValueError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç vLLM")

        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ vLLM: {e}")
            raise
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
            raise

# =============================================================================
# –ö–ê–ß–ï–°–¢–í–û –ò –í–ê–õ–ò–î–ê–¶–ò–Ø (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) 
# =============================================================================

class QualityAssuranceOperator(PDFConverterBaseOperator):
    """–û–ø–µ—Ä–∞—Ç–æ—Ä –¥–ª—è 5-—É—Ä–æ–≤–Ω–µ–≤–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (DAG 4)"""

    @apply_defaults
    def __init__(
        self,
        validation_levels: List[str] = None,
        quality_target: float = 100.0,
        auto_correct: bool = True,
        **kwargs
    ):
        super().__init__(
            service_endpoint=os.getenv('QA_SERVICE_ENDPOINT', 'http://quality-assurance:8002'),
            **kwargs
        )
        
        self.validation_levels = validation_levels or ['ocr', 'visual', 'ast', 'content', 'correction']
        self.quality_target = quality_target
        self.auto_correct = auto_correct

    def execute(self, context: Context) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ 5-—É—Ä–æ–≤–Ω–µ–≤–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        logger.info("üîç –ó–∞–ø—É—Å–∫ 5-—É—Ä–æ–≤–Ω–µ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤
        upstream_data = context['task_instance'].xcom_pull(task_ids=None)
        original_file = context['dag_run'].conf.get('input_file')

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        validation_data = {
            'original_pdf': original_file,
            'processed_content': upstream_data,
            'validation_levels': self.validation_levels,
            'quality_target': self.quality_target,
            'auto_correct': self.auto_correct,
            'task_config': context['dag_run'].conf
        }

        # –ó–∞–ø—É—Å–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        result = self.make_request('/api/v1/validate', data=validation_data)

        validation_results = {
            'overall_score': result.get('overall_score', 0.0),
            'level_scores': result.get('level_scores', {}),
            'validation_report': result.get('report', {}),
            'corrections_applied': result.get('corrections', []),
            'final_content': result.get('final_content', ''),
            'quality_passed': result.get('overall_score', 0.0) >= self.quality_target
        }

        if not validation_results['quality_passed']:
            logger.warning(f"‚ö†Ô∏è –ö–∞—á–µ—Å—Ç–≤–æ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ: {validation_results['overall_score']:.2f}% < {self.quality_target}%")
        else:
            logger.info(f"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ: {validation_results['overall_score']:.2f}%")

        return validation_results

# =============================================================================
# NOTIFICATION UTILITIES (—Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏ –¥–ª—è Dynamic vLLM)
# =============================================================================

class NotificationUtils:
    """–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π"""

    @staticmethod
    def send_success_notification(context: Context, results: Dict[str, Any]):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± —É—Å–ø–µ—à–Ω–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
        task_id = context['dag_run'].dag_id
        dag_run_id = context['dag_run'].run_id

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª—è—Ö –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        model_info = ""
        if 'transformation_stats' in results:
            model_info += f"\n- Content Model: {results['transformation_stats'].get('model_used', 'unknown')}"
        if 'translation_stats' in results:
            model_info += f"\n- Translation Model: {results['translation_stats'].get('model_used', 'unknown')}"

        message = f"""
‚úÖ PDF –∫–æ–Ω–≤–µ–π–µ—Ä v4.0 —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π OCR –∑–∞–≤–µ—Ä—à–µ–Ω

–ó–∞–¥–∞—á–∞: {task_id}
Run ID: {dag_run_id}
–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {context['dag_run'].end_date - context['dag_run'].start_date if context['dag_run'].end_date else 'N/A'}

ü§ñ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:{model_info}

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏:
- –û–±—â–∏–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞: {results.get('overall_score', 'N/A')}%
- –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞: {'‚úÖ –î–∞' if results.get('quality_passed') else '‚ùå –ù–µ—Ç'}
"""

        logger.info(message)
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–∫—É –≤ Slack, email –∏ —Ç.–¥.

    @staticmethod
    def send_failure_notification(context: Context, exception: Exception):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ"""
        task_id = context['task_instance'].task_id
        dag_id = context['dag_run'].dag_id

        message = f"""
‚ùå –û—à–∏–±–∫–∞ –≤ PDF –∫–æ–Ω–≤–µ–π–µ—Ä–µ v4.0

DAG: {dag_id}
Task: {task_id}
–û—à–∏–±–∫–∞: {str(exception)}

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å Document Processor: {os.getenv('DOCUMENT_PROCESSOR_URL', 'http://document-processor:8001')}/status
"""

        logger.error(message)

# =============================================================================
# SHARED UTILITIES (–æ–±–Ω–æ–≤–ª–µ–Ω—ã)
# =============================================================================

class SharedUtils:
    """–û–±—â–∏–µ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è –≤—Å–µ—Ö DAG"""

    @staticmethod
    def prepare_output_path(filename: str, target_language: str, timestamp: int) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—É—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        base_name = os.path.splitext(filename)[0]
        output_dir = f"/app/output/{target_language}"
        os.makedirs(output_dir, exist_ok=True)
        return f"{output_dir}/{timestamp}_{base_name}.md"

    @staticmethod
    def save_final_result(content: str, output_path: str, metadata: Dict = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        if metadata:
            metadata_path = output_path.replace('.md', '_metadata.json')
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞ (1000:1000)
        try:
            os.chown(output_path, 1000, 1000)
            if metadata:
                os.chown(metadata_path, 1000, 1000)
        except:
            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ

    @staticmethod
    def validate_input_file(file_path: str) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ PDF —Ñ–∞–π–ª–∞"""
        if not os.path.exists(file_path):
            return False
        
        if not file_path.lower().endswith('.pdf'):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞ (–º–∞–∫—Å 500MB)
        max_size = 500 * 1024 * 1024
        if os.path.getsize(file_path) > max_size:
            return False
        
        return True

    @staticmethod
    def get_processing_stats(start_time: datetime, end_time: datetime = None) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        end_time = end_time or datetime.now()
        duration = end_time - start_time
        
        return {
            'start_time': start_time.isoformat(),
            'end_time': end_time.isoformat(),
            'duration_seconds': duration.total_seconds(),
            'duration_human': str(duration)
        }

    @staticmethod
    def check_document_processor_health() -> Dict[str, Any]:
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è Document Processor"""
        processor_url = os.getenv('DOCUMENT_PROCESSOR_URL', 'http://document-processor:8001')
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º health endpoint
            response = requests.get(f"{processor_url}/health", timeout=10)
            if response.status_code == 200:
                health_data = response.json()
                
                # –ü–æ–ª—É—á–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—É—Å–µ
                try:
                    status_response = requests.get(f"{processor_url}/status", timeout=10)
                    if status_response.status_code == 200:
                        status_data = status_response.json()
                        health_data.update(status_data)
                except:
                    pass
                
                return health_data
            else:
                return {"status": "unhealthy", "error": f"HTTP {response.status_code}"}
        
        except Exception as e:
            return {"status": "unreachable", "error": str(e)}

# =============================================================================
# CONFIGURATION UTILITIES (–æ–±–Ω–æ–≤–ª–µ–Ω—ã)
# =============================================================================

class ConfigUtils:
    """–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π"""

    @staticmethod
    def get_service_config() -> Dict[str, str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤"""
        return {
            'vllm': os.getenv('VLLM_SERVER_URL', 'http://vllm-server:8000'),
            'document_processor': os.getenv('DOCUMENT_PROCESSOR_URL', 'http://document-processor:8001'),
            'qa_service': os.getenv('QA_SERVICE_ENDPOINT', 'http://quality-assurance:8002'),
            'translator': os.getenv('TRANSLATOR_URL', 'http://translator:8003')
        }

    @staticmethod
    def get_model_config() -> Dict[str, str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π –¥–ª—è Dynamic vLLM"""
        return {
            'content_transformation_model': 'Qwen/Qwen2.5-VL-32B-Instruct',
            'translation_model': 'Qwen/Qwen3-30B-A3B-Instruct-2507',
            'dynamic_loading_enabled': True,
            'vllm_endpoint': '/v1/chat/completions',
            'model_status_endpoint': '/v1/models/status',
            'model_swap_endpoint': '/v1/models/swap'
        }

    @staticmethod
    def get_processing_defaults() -> Dict[str, Any]:
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        return {
            'use_ocr': False,  # ‚úÖ –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é OCR –æ—Ç–∫–ª—é—á–µ–Ω –¥–ª—è —Ü–∏—Ñ—Ä–æ–≤—ã—Ö PDF
            'ocr_languages': 'chi_sim,eng,rus',
            'quality_target': 100.0,
            'auto_correct': True,
            'preserve_technical_terms': True,
            'max_file_size_mb': 500,
            'batch_size': 4,
            'disable_thinking': True,
            'dynamic_model_loading': True,
            'model_swap_timeout': 300,
            'vram_optimization': True
        }

    @staticmethod
    def get_dynamic_vllm_settings() -> Dict[str, Any]:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è Dynamic vLLM Server"""
        return {
            'auto_model_selection': True,
            'model_swap_timeout': 300,
            'memory_cleanup_aggressive': True,
            'health_check_interval': 30,
            'supported_tasks': ['content_transformation', 'translation'],
            'model_aliases': {
                'content-transformer': 'content_transformation',
                'translator': 'translation'
            }
        }