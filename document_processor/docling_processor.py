#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô Docling Processor –¥–ª—è PDF Converter Pipeline v4.0
‚úÖ –£–°–¢–†–ê–ù–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´:
- –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ use_ocr —Ñ–ª–∞–≥–∞
- –£—Å–ª–æ–≤–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OCR –¥–≤–∏–∂–∫–æ–≤
- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ DocumentConverter
- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –ø–æ—Ç–µ—Ä—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
"""

import os
import sys
import asyncio
import logging
from typing import Dict, List, Optional, Any, Tuple, Union
from pathlib import Path
import tempfile
import json
from dataclasses import dataclass
from datetime import datetime

# Docling –∏–º–ø–æ—Ä—Ç—ã
from docling.document_converter import DocumentConverter
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions
from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
import structlog
import numpy as np
from PIL import Image
import pandas as pd
import re

# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π
import shutil
from pathlib import Path

# Prometheus –º–µ—Ç—Ä–∏–∫–∏
from prometheus_client import Counter, Histogram, Gauge

# =============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò –ú–ï–¢–†–ò–ö–ò
# =============================================================================

logger = structlog.get_logger("docling_processor")

# –ú–µ—Ç—Ä–∏–∫–∏ Prometheus
docling_requests = Counter('docling_requests_total', 'Total Docling processing requests', ['status'])
docling_duration = Histogram('docling_processing_duration_seconds', 'Docling processing duration')
docling_pages = Histogram('docling_pages_processed', 'Pages processed by Docling')
docling_elements = Counter('docling_elements_extracted', 'Elements extracted by type', ['element_type'])

@dataclass
class DoclingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Docling –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
    model_path: str = "/mnt/storage/models/shared/docling"
    use_gpu: bool = False
    max_workers: int = 4
    timeout: int = 300
    cache_dir: str = "/app/cache"
    temp_dir: str = "/app/temp"
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
    extract_images: bool = True
    extract_tables: bool = True
    extract_formulas: bool = True
    high_quality_ocr: bool = True
    
    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ OCR –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    enable_ocr_by_default: bool = False  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é OCR –æ—Ç–∫–ª—é—á–µ–Ω
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    chinese_language_support: bool = True
    preserve_chinese_layout: bool = True
    mixed_language_mode: bool = True

# =============================================================================
# –û–°–ù–û–í–ù–´–ï –¢–ò–ü–´ –î–ê–ù–ù–´–•
# =============================================================================

@dataclass
class ProcessedElement:
    """–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    element_type: str
    content: str
    bbox: Optional[Tuple[float, float, float, float]] = None
    page_number: int = 0
    confidence: float = 1.0
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

@dataclass
class DocumentStructure:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    title: Optional[str] = None
    authors: List[str] = None
    sections: List[Dict[str, Any]] = None
    tables: List[Dict[str, Any]] = None
    images: List[Dict[str, Any]] = None
    formulas: List[Dict[str, Any]] = None
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        if self.authors is None:
            self.authors = []
        if self.sections is None:
            self.sections = []
        if self.tables is None:
            self.tables = []
        if self.images is None:
            self.images = []
        if self.formulas is None:
            self.formulas = []
        if self.metadata is None:
            self.metadata = {}

# =============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô DOCLING PROCESSOR –ö–õ–ê–°–°
# =============================================================================

class DoclingProcessor:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF —á–µ—Ä–µ–∑ Docling"""

    def __init__(self, config: Optional[DoclingConfig] = None):
        self.config = config or DoclingConfig()
        self.logger = structlog.get_logger("docling_processor")
        
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –ù–ï –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –≤ __init__
        self.converter: Optional[DocumentConverter] = None
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        Path(self.config.cache_dir).mkdir(parents=True, exist_ok=True)
        Path(self.config.temp_dir).mkdir(parents=True, exist_ok=True)
        
        self.logger.info("DoclingProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –±–µ–∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ OCR")

    def _initialize_converter(self, use_ocr: bool = False):
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º OCR —Ñ–ª–∞–≥–æ–º"""
        try:
            from docling.datamodel.base_models import InputFormat
            from docling.document_converter import PdfFormatOption

            # ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø OCR
            pdf_format_options = PdfFormatOption(
                backend=PyPdfiumDocumentBackend,
                pipeline_options=PdfPipelineOptions(
                    enable_layout_analysis=True,
                    enable_ocr=use_ocr,  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
                    images_scale=1.0,
                    generate_page_images=False,
                    generate_table_images=False,
                    generate_picture_images=False
                )
            )

            self.converter = DocumentConverter(
                format_options={
                    InputFormat.PDF: pdf_format_options
                }
            )

            self.logger.info(f"Docling converter initialized with OCR: {use_ocr}")
            return True

        except Exception as e:
            self.logger.error(f"Failed to initialize Docling converter: {e}")
            raise

    async def process_document(
        self, 
        pdf_path: str, 
        output_dir: str, 
        use_ocr: bool = False  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é False
    ) -> DocumentStructure:
        """
        ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        start_time = datetime.now()
        
        try:
            docling_requests.labels(status='started').inc()
            
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ OCR –≤ –Ω–∞—á–∞–ª–µ
            self.logger.info(f"üì• OCR setting: {use_ocr}")
            
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ñ–ª–∞–≥–æ–º OCR
            if not self.converter:
                self._initialize_converter(use_ocr=use_ocr)
                self.logger.info(f"‚ñ∂ Docling initialised with OCR: {use_ocr}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            if not Path(pdf_path).exists():
                raise FileNotFoundError(f"PDF file not found: {pdf_path}")

            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô –≤—ã–∑–æ–≤ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞
            self.logger.info(f"Starting Docling conversion for: {pdf_path}")
            conv_result = self.converter.convert(pdf_path)
            
            # ‚úÖ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            self.logger.info(f"üîç DEBUG: Document pages type: {type(conv_result.document.pages)}")
            self.logger.info(f"üîç DEBUG: Document pages count: {len(conv_result.document.pages)}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –í–°–ï –∞—Ç—Ä–∏–±—É—Ç—ã –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if conv_result.document.pages:
                first_page_key = list(conv_result.document.pages.keys())[0]
                first_page = conv_result.document.pages[first_page_key]
                all_attrs = [attr for attr in dir(first_page) if not attr.startswith('_')]
                self.logger.info(f"üîç DEBUG: Page {first_page_key} ALL attributes: {all_attrs}")

            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞
            document_structure = await self._extract_document_structure_fixed(
                conv_result, output_dir
            )

            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            duration = (datetime.now() - start_time).total_seconds()
            docling_duration.observe(duration)
            docling_pages.observe(len(conv_result.document.pages))
            docling_requests.labels(status='completed').inc()

            self.logger.info(
                f"Document processed successfully in {duration:.2f}s",
                elements=len(document_structure.sections) + len(document_structure.tables),
                pages=len(conv_result.document.pages)
            )

            return document_structure

        except Exception as e:
            docling_requests.labels(status='error').inc()
            self.logger.error(f"Error processing document {pdf_path}: {e}")
            raise

    async def _extract_document_structure_fixed(
        self,
        conv_result,
        output_dir: str
    ) -> DocumentStructure:
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å –ø–æ–ª–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º"""
        
        document = conv_result.document
        structure = DocumentStructure()

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        structure.metadata = {
            "total_pages": len(document.pages),
            "processing_time": datetime.now().isoformat(),
            "docling_version": "1.5.0",
            "language_detected": "mixed"
        }

        try:
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            full_text = ""
            
            # –ú–ï–¢–û–î 1: export_to_text (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –¥–ª—è —Ü–∏—Ñ—Ä–æ–≤—ã—Ö PDF)
            try:
                exported_text = document.export_to_text()
                if exported_text and len(exported_text.strip()) > 10:
                    full_text = exported_text
                    self.logger.info(f"‚úÖ SUCCESS: Extracted {len(full_text)} chars via export_to_text")
                else:
                    self.logger.warning("export_to_text returned empty or short text")
            except Exception as e:
                self.logger.warning(f"export_to_text failed: {e}")

            # –ú–ï–¢–û–î 2: export_to_markdown (—Ä–µ–∑–µ—Ä–≤–Ω—ã–π —Å–ø–æ—Å–æ–±)
            if not full_text:
                try:
                    markdown_text = document.export_to_markdown()
                    if markdown_text and len(markdown_text.strip()) > 10:
                        full_text = markdown_text
                        self.logger.info(f"‚úÖ SUCCESS: Extracted {len(full_text)} chars via export_to_markdown")
                    else:
                        self.logger.warning("export_to_markdown returned empty or short text")
                except Exception as e:
                    self.logger.warning(f"export_to_markdown failed: {e}")

            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–æ–∑–¥–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É sections
            if full_text:
                structure.sections = await self._parse_exported_text_improved(full_text)
                structure.title = await self._extract_title_from_text(full_text)
            else:
                # Fallback - —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                structure.sections = [{
                    'title': 'Document Content',
                    'level': 1,
                    'page': 1,
                    'content': f'Processed document with {len(document.pages)} pages using Docling',
                    'subsections': []
                }]

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
            if self.config.extract_tables:
                structure.tables = await self._extract_tables_fixed(document, output_dir)

            if self.config.extract_images:
                structure.images = await self._extract_images_fixed(document, output_dir)

            self.logger.info(
                f"Final extraction result: {len(structure.sections)} sections, "
                f"{len(structure.tables)} tables, {len(structure.images)} images"
            )

        except Exception as e:
            self.logger.error(f"Error in document structure extraction: {e}")
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–∏ –æ—à–∏–±–∫–µ
            structure.sections = [{
                'title': 'Error Processing Document',
                'level': 1,
                'page': 1,
                'content': f'Document processing encountered errors: {str(e)}',
                'subsections': []
            }]

        return structure

    async def _parse_exported_text_improved(self, full_text: str) -> List[Dict[str, Any]]:
        """‚úÖ –£–õ–£–ß–®–ï–ù–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ –≤ —Å–µ–∫—Ü–∏–∏"""
        sections = []
        
        try:
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã, —Å–æ—Ö—Ä–∞–Ω—è—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            paragraphs = [p.strip() for p in full_text.split('\n\n') if p.strip()]
            
            current_section = None
            
            for i, paragraph in enumerate(paragraphs):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
                if self._looks_like_heading_improved(paragraph):
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Å–µ–∫—Ü–∏—é
                    if current_section and current_section['content'].strip():
                        sections.append(current_section)
                    
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ–∫—Ü–∏—é
                    current_section = {
                        'title': paragraph[:200],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∑–∞–≥–æ–ª–æ–≤–∫–∞
                        'level': self._get_heading_level_from_text_improved(paragraph),
                        'page': 1,  # TODO: –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                        'content': '',
                        'subsections': []
                    }
                else:
                    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –∫ —Ç–µ–∫—É—â–µ–π —Å–µ–∫—Ü–∏–∏
                    if current_section:
                        current_section['content'] += paragraph + '\n\n'
                    else:
                        # –°–æ–∑–¥–∞–µ–º —Å–µ–∫—Ü–∏—é –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
                        current_section = {
                            'title': 'Document Content',
                            'level': 1,
                            'page': 1,
                            'content': paragraph + '\n\n',
                            'subsections': []
                        }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–µ–∫—Ü–∏—é
            if current_section and current_section['content'].strip():
                sections.append(current_section)
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –Ω–∏ –æ–¥–Ω–æ–π —Å–µ–∫—Ü–∏–∏, —Å–æ–∑–¥–∞–µ–º –æ–¥–Ω—É —Å –≤—Å–µ–º —Ç–µ–∫—Å—Ç–æ–º
            if not sections:
                sections = [{
                    'title': 'Document Content',
                    'level': 1,
                    'page': 1,
                    'content': full_text,
                    'subsections': []
                }]
            
            self.logger.info(f"Parsed {len(sections)} sections from exported text")
            
        except Exception as e:
            self.logger.error(f"Error parsing exported text: {e}")
            sections = [{
                'title': 'Document Content',
                'level': 1,
                'page': 1,
                'content': full_text,
                'subsections': []
            }]
        
        return sections

    def _looks_like_heading_improved(self, text: str) -> bool:
        """‚úÖ –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤"""
        text = text.strip()
        
        # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç
        if len(text) < 3 or len(text) > 200:
            return False
        
        # –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –¥–≤–æ–µ—Ç–æ—á–∏–µ–º –∏–ª–∏ —Ç–æ—á–∫–æ–π –ø–æ—Å–ª–µ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        if text.endswith(':') or (text.endswith('.') and len(text) < 50):
            return True
        
        # –°–æ–¥–µ—Ä–∂–∏—Ç —Ü–∏—Ñ—Ä—ã –≤ –Ω–∞—á–∞–ª–µ (–Ω—É–º–µ—Ä–∞—Ü–∏—è)
        if re.match(r'^\d+[\.\)]\s+', text):
            return True
        
        # –í–µ—Å—å –≤ –≤–µ—Ä—Ö–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ –∏ –∫–æ—Ä–æ—Ç–∫–∏–π
        if text.isupper() and len(text) < 100:
            return True
        
        # –°–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (–≤–∫–ª—é—á–∞—è –∫–∏—Ç–∞–π—Å–∫–∏–µ)
        heading_keywords = ['Á´†', 'ËäÇ', 'ÈÉ®ÂàÜ', 'Á¨¨', 'ÁØá', 'chapter', 'section', 'part', 'Ê¶ÇËø∞', '‰ªãÁªç', 'ÊÄªÁªì']
        if any(keyword in text.lower() for keyword in heading_keywords):
            return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –º–∞—Ä–∫–µ—Ä–æ–≤ —Ä–∞–∑–¥–µ–ª–æ–≤ –≤ –∫–∏—Ç–∞–π—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
        if re.search(r'[Á¨¨]\s*[‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅ\d]+\s*[Á´†ËäÇÈÉ®ÂàÜ]', text):
            return True
        
        return False

    def _get_heading_level_from_text_improved(self, text: str) -> int:
        """‚úÖ –£–õ–£–ß–®–ï–ù–ù–û–ï –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        # –ï—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —Ü–∏—Ñ—Ä—ã - —É—Ä–æ–≤–µ–Ω—å 1
        if re.match(r'^\d+[\.\)]', text):
            return 1
        
        # –ï—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥—É—Ä–æ–≤–Ω–∏ (1.1, 1.1.1)
        if re.match(r'^\d+\.\d+', text):
            return 2
        
        if re.match(r'^\d+\.\d+\.\d+', text):
            return 3
        
        # –ö–∏—Ç–∞–π—Å–∫–∏–µ –º–∞—Ä–∫–µ—Ä—ã
        if re.search(r'[Á¨¨]\s*[‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅ]\s*[Á´†]', text):
            return 1
        
        if re.search(r'[Á¨¨]\s*[‰∏Ä‰∫å‰∏âÂõõ‰∫îÂÖ≠‰∏ÉÂÖ´‰πùÂçÅ]\s*[ËäÇ]', text):
            return 2
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return 1

    async def _extract_title_from_text(self, text: str) -> Optional[str]:
        """‚úÖ –£–õ–£–ß–®–ï–ù–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        try:
            lines = text.split('\n')
            for line in lines[:15]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 15 —Å—Ç—Ä–æ–∫
                line = line.strip()
                if line and len(line) > 5 and len(line) < 200:
                    # –£–±–∏—Ä–∞–µ–º Markdown –∑–∞–≥–æ–ª–æ–≤–∫–∏
                    title = line.lstrip('#').strip()
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä–æ–∫–∞
                    if not any(skip in title.lower() for skip in ['http', 'www', 'page', 'È°µ']):
                        return title
            return None
        except Exception:
            return None

    async def _extract_tables_fixed(self, document, output_dir: str) -> List[Dict[str, Any]]:
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü"""
        tables = []
        try:
            # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –∏–∑ Docling –¥–æ–∫—É–º–µ–Ω—Ç–∞
            # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
            pass
        except Exception as e:
            self.logger.warning(f"Table extraction failed: {e}")
        
        return tables

    async def _extract_images_fixed(self, document, output_dir: str) -> List[Dict[str, Any]]:
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        images = []
        try:
            # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ Docling –¥–æ–∫—É–º–µ–Ω—Ç–∞
            # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
            pass
        except Exception as e:
            self.logger.warning(f"Image extraction failed: {e}")
        
        return images

    def export_to_markdown(self, structure: DocumentStructure, output_path: str) -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ Markdown"""
        try:
            md_content = []

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            if structure.title:
                md_content.append(f"# {structure.title}\n")

            # –†–∞–∑–¥–µ–ª—ã
            for section in structure.sections:
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ä–∞–∑–¥–µ–ª–∞
                level_prefix = "#" * section['level']
                md_content.append(f"{level_prefix} {section['title']}\n")

                # –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞
                if section['content']:
                    md_content.append(f"{section['content']}\n")

            # –¢–∞–±–ª–∏—Ü—ã
            if structure.tables:
                md_content.append("## Tables\n")
                for table in structure.tables:
                    md_content.append(f"### Table {table['id']} (Page {table['page']})\n")
                    md_content.append(f"Rows: {table['rows']}, Columns: {table['columns']}\n")
                    md_content.append(f"File: `{table['file_path']}`\n\n")

            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if structure.images:
                md_content.append("## Images\n")
                for image in structure.images:
                    md_content.append(f"### Image {image['id']} (Page {image['page']})\n")
                    md_content.append(f"![Image {image['id']}]({image['file_path']})\n")
                    if image.get('caption'):
                        md_content.append(f"*{image['caption']}*\n\n")
                    else:
                        md_content.append("\n")

            # –§–æ—Ä–º—É–ª—ã
            if structure.formulas:
                md_content.append("## Formulas\n")
                for formula in structure.formulas:
                    md_content.append(f"### Formula {formula['id']} (Page {formula['page']})\n")
                    md_content.append(f"```\n{formula.get('content', '')}\n```\n\n")

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(md_content))

            self.logger.info(f"Markdown exported to: {output_path}")

            return '\n'.join(md_content)

        except Exception as e:
            self.logger.error(f"Error exporting to markdown: {e}")
            raise

# =============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# =============================================================================

def create_docling_processor(config: Optional[DoclingConfig] = None) -> DoclingProcessor:
    """–§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è Docling –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
    return DoclingProcessor(config)

async def process_pdf_with_docling(
    pdf_path: str,
    output_dir: str,
    use_ocr: bool = False,  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é False
    config: Optional[DoclingConfig] = None
) -> DocumentStructure:
    """
    ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF
    """
    processor = create_docling_processor(config)
    return await processor.process_document(pdf_path, output_dir, use_ocr=use_ocr)

# =============================================================================
# –û–°–ù–û–í–ù–û–ô –ë–õ–û–ö –î–õ–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø
# =============================================================================

if __name__ == "__main__":
    async def main():
        config = DoclingConfig()
        processor = DoclingProcessor(config)

        pdf_path = "/app/temp/test_document.pdf"
        output_dir = "/app/temp/output"

        if Path(pdf_path).exists():
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–µ—Ä–µ–¥–∞–µ–º use_ocr=False –¥–ª—è —Ü–∏—Ñ—Ä–æ–≤—ã—Ö PDF
            structure = await processor.process_document(
                pdf_path, 
                output_dir, 
                use_ocr=False
            )

            md_path = Path(output_dir) / "document.md"
            processor.export_to_markdown(structure, str(md_path))

            print(f"Document processed successfully!")
            print(f"Sections: {len(structure.sections)}")
            print(f"Tables: {len(structure.tables)}")
            print(f"Images: {len(structure.images)}")
        else:
            print(f"Test file not found: {pdf_path}")

    asyncio.run(main())